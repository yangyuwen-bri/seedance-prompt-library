#!/usr/bin/env python3
"""
åˆå¹¶ data/raw/*.json ä¸­çš„æ‰€æœ‰æ¨æ–‡æ•°æ®ï¼ŒæŒ‰ tweet ID å»é‡ã€‚
è¾“å‡º data/all_tweets.json
"""

import os
import json
import glob

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))


def merge_and_dedup():
    """åˆå¹¶æ‰€æœ‰åŸå§‹æ•°æ®æ–‡ä»¶å¹¶å»é‡"""
    raw_dir = os.path.join(BASE_DIR, 'data', 'raw')
    output_file = os.path.join(BASE_DIR, 'data', 'all_tweets.json')

    # è¯»å–ç°æœ‰åˆå¹¶æ•°æ®
    existing = {}
    if os.path.exists(output_file):
        with open(output_file, 'r', encoding='utf-8') as f:
            for tweet in json.load(f):
                tid = tweet.get('id') or tweet.get('url', '')
                if tid:
                    existing[tid] = tweet

    print(f"ğŸ“‚ ç°æœ‰æ•°æ®: {len(existing)} æ¡")

    # è¯»å–æ‰€æœ‰ raw æ–‡ä»¶
    raw_files = sorted(glob.glob(os.path.join(raw_dir, '*.json')))
    new_count = 0

    for fpath in raw_files:
        fname = os.path.basename(fpath)
        with open(fpath, 'r', encoding='utf-8') as f:
            tweets = json.load(f)

        file_new = 0
        for tweet in tweets:
            tid = tweet.get('id') or tweet.get('url', '')
            if tid and tid not in existing:
                existing[tid] = tweet
                file_new += 1
                new_count += 1

        print(f"  ğŸ“„ {fname}: {len(tweets)} æ¡, æ–°å¢ {file_new}")

    # æŒ‰æ—¶é—´æ’åºï¼ˆæœ€æ–°åœ¨å‰ï¼‰
    all_tweets = sorted(
        existing.values(),
        key=lambda x: x.get('createdAt', ''),
        reverse=True
    )

    # ä¿å­˜
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_tweets, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… åˆå¹¶å®Œæˆ: {output_file}")
    print(f"   æ€»è®¡: {len(all_tweets)} æ¡, æœ¬æ¬¡æ–°å¢: {new_count}")
    return output_file


if __name__ == '__main__':
    merge_and_dedup()
