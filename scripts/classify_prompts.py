#!/usr/bin/env python3
"""
ä½¿ç”¨ Gemini REST API å¯¹ prompt ç´ æè¿›è¡Œæ™ºèƒ½åˆ†ç±»ã€‚
æ‰¹é‡å¤„ç†ï¼Œæ¯æ¬¡çº¦ 25 æ¡ï¼Œå‡å°‘ API è°ƒç”¨ã€‚
åªå¯¹æœªåˆ†ç±»çš„ prompt è¿›è¡Œåˆ†ç±»ï¼ˆå¢é‡å¤„ç†ï¼‰ã€‚
"""

import os
import json
import time
import requests
from dotenv import load_dotenv

load_dotenv()

GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
BATCH_SIZE = 25
GEMINI_MODEL = 'gemini-2.0-flash'
GEMINI_URL = f'https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent'


SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªAIè§†é¢‘å†…å®¹åˆ†ç±»ä¸“å®¶ã€‚è¯·ä¸ºä»¥ä¸‹ Seedance AI è§†é¢‘ç”Ÿæˆçš„ prompt è¿›è¡Œåˆ†æã€‚

å¯¹æ¯æ¡ promptï¼Œè¯·è¿”å›ï¼š
1. tags: 1-2ä¸ªæœ€åŒ¹é…çš„åˆ†ç±»æ ‡ç­¾ï¼ˆä»ä»¥ä¸‹é€‰æ‹©ï¼‰
2. quality_score: prompt è´¨é‡è¯„åˆ† 1-5ï¼ˆ5=éå¸¸è¯¦ç»†ä¸“ä¸šï¼Œ1=è¿‡äºç®€å•ï¼‰
3. summary: ä¸€å¥è¯ä¸­æ–‡æ‘˜è¦ï¼ˆæè¿°è¿™ä¸ªpromptä¼šç”Ÿæˆä»€ä¹ˆæ ·çš„è§†é¢‘ï¼‰

å¯é€‰åˆ†ç±»æ ‡ç­¾ï¼š
- ğŸ¬ ç”µå½±/å½±è§†
- ğŸŒ åŠ¨æ¼«
- ğŸ“º å¹¿å‘Š/å•†ä¸š
- ğŸ¨ è‰ºæœ¯/åˆ›æ„
- ğŸ˜‚ æç¬‘/Meme
- ğŸŒ å†™å®/çºªå®
- ğŸ® æ¸¸æˆ
- ğŸµ éŸ³ä¹/MV
- ğŸ’¡ åˆ›æ„/å®éªŒ
- ğŸ”¥ åäºº/IP
- ğŸ·ï¸ å…¶ä»–ï¼ˆä»¥ä¸Šç±»åˆ«éƒ½ä¸åŒ¹é…æ—¶ä½¿ç”¨ï¼‰

æ³¨æ„ï¼šå¦‚æœ prompt æ˜ç¡®ä¸å±äºä»¥ä¸Šä»»ä½•ä¸€ç±»ï¼Œè¯·ä½¿ç”¨"ğŸ·ï¸ å…¶ä»–"ã€‚ä¸è¦å¼ºè¡Œå½’ç±»ã€‚

è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹ JSON æ•°ç»„æ ¼å¼è¿”å›ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ï¼š
[
  {"id": 1, "tags": ["ğŸŒ åŠ¨æ¼«", "ğŸ˜‚ æç¬‘/Meme"], "quality_score": 3, "summary": "æµ·ç»µå®å®æ´¾å¤§æ˜Ÿä¸åšå°”ç‰¹èµ›è·‘"},
  ...
]"""


def classify_with_gemini(prompts_batch):
    """è°ƒç”¨ Gemini REST API æ‰¹é‡åˆ†ç±» prompt"""
    prompt_list = ""
    for i, p in enumerate(prompts_batch):
        text = p["prompt"][:200]  # æˆªæ–­è¿‡é•¿çš„ prompt
        prompt_list += f'{i+1}. """{text}"""\n'

    user_prompt = f"è¯·åˆ†ç±»ä»¥ä¸‹ {len(prompts_batch)} æ¡ promptï¼š\n\n{prompt_list}"

    payload = {
        "contents": [
            {
                "parts": [
                    {"text": SYSTEM_PROMPT + "\n\n" + user_prompt}
                ]
            }
        ],
        "generationConfig": {
            "temperature": 0.3,
            "maxOutputTokens": 4096,
        }
    }

    try:
        resp = requests.post(
            GEMINI_URL,
            params={"key": GEMINI_API_KEY},
            json=payload,
            timeout=60
        )
        resp.raise_for_status()
        data = resp.json()

        # æå–æ–‡æœ¬
        text = data['candidates'][0]['content']['parts'][0]['text']
        text = text.strip()

        # å»æ‰å¯èƒ½çš„ markdown code block
        if text.startswith('```'):
            text = text.split('\n', 1)[1]
            text = text.rsplit('```', 1)[0]
        text = text.strip()

        results = json.loads(text)
        return results

    except requests.exceptions.HTTPError as e:
        print(f"  âš ï¸ HTTP é”™è¯¯: {e}")
        if resp.status_code == 429:
            print("  â³ è§¦å‘é™æµï¼Œç­‰å¾… 30 ç§’...")
            time.sleep(30)
        return None
    except (json.JSONDecodeError, KeyError, IndexError) as e:
        print(f"  âš ï¸ è§£æå“åº”å¤±è´¥: {e}")
        return None
    except Exception as e:
        print(f"  âš ï¸ API è°ƒç”¨å¤±è´¥: {e}")
        return None


def classify_prompts():
    """å¯¹ prompt_library.json ä¸­æœªåˆ†ç±»çš„ prompt è¿›è¡Œåˆ†ç±»"""
    library_file = os.path.join(BASE_DIR, 'data', 'prompt_library.json')

    if not GEMINI_API_KEY:
        print("âŒ GEMINI_API_KEY æœªè®¾ç½®ï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®")
        print("   è·³è¿‡åˆ†ç±»æ­¥éª¤ï¼Œä¿ç•™ç©ºæ ‡ç­¾")
        return

    if not os.path.exists(library_file):
        print("âŒ prompt_library.json ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ extract_prompts.py")
        return

    with open(library_file, 'r', encoding='utf-8') as f:
        library = json.load(f)

    prompts = library['prompts']

    # æ‰¾å‡ºæœªåˆ†ç±»çš„ prompt
    unclassified = [(i, p) for i, p in enumerate(prompts) if not p.get('tags')]
    print(f"ğŸ“Š æ€» prompt: {len(prompts)}, å¾…åˆ†ç±»: {len(unclassified)}")

    if not unclassified:
        print("âœ… æ‰€æœ‰ prompt å·²åˆ†ç±»ï¼Œæ— éœ€å¤„ç†")
        return

    # æ‰¹é‡åˆ†ç±»
    total_batches = (len(unclassified) + BATCH_SIZE - 1) // BATCH_SIZE
    classified_count = 0

    for batch_idx in range(0, len(unclassified), BATCH_SIZE):
        batch = unclassified[batch_idx:batch_idx + BATCH_SIZE]
        batch_num = batch_idx // BATCH_SIZE + 1
        print(f"\nğŸ”„ æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch)} æ¡)...")

        batch_prompts = [p for _, p in batch]
        results = classify_with_gemini(batch_prompts)

        if results:
            for result in results:
                idx_in_batch = result['id'] - 1
                if 0 <= idx_in_batch < len(batch):
                    original_idx = batch[idx_in_batch][0]
                    prompts[original_idx]['tags'] = result.get('tags', [])
                    prompts[original_idx]['quality_score'] = result.get('quality_score', 0)
                    prompts[original_idx]['summary'] = result.get('summary', '')
                    classified_count += 1
            print(f"  âœ… æˆåŠŸåˆ†ç±» {len(results)} æ¡")
        else:
            print(f"  âŒ æ‰¹æ¬¡ {batch_num} å¤±è´¥ï¼Œè·³è¿‡")

        # æ¯æ‰¹æ¬¡åä¿å­˜ï¼ˆé˜²æ­¢ä¸­æ–­ä¸¢æ•°æ®ï¼‰
        library['prompts'] = prompts
        with open(library_file, 'w', encoding='utf-8') as f:
            json.dump(library, f, ensure_ascii=False, indent=2)

        # é¿å… API é™æµ
        if batch_idx + BATCH_SIZE < len(unclassified):
            time.sleep(3)

    print(f"\nâœ… åˆ†ç±»å®Œæˆ: {classified_count}/{len(unclassified)} æ¡")
    print(f"ğŸ“ å·²æ›´æ–°: {library_file}")


if __name__ == '__main__':
    classify_prompts()
